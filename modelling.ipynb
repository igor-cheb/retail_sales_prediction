{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall idea is that we will implement linear and tree based models first and try to ansamble them. Further will implement recurrent NN and compare the two models.\n",
    "Data normalisation required for linear or NN models will be done with the help of sklearn pipeline which will include both motel and data transofrmation steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "from src.ToyModel import ToyModel\n",
    "from src.utilities import run_cv\n",
    "from src.FeatureGenerator import FeatureGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV data initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating data generators\n",
    "feat_generator = FeatureGenerator()\n",
    "\n",
    "# initiating cv splitter\n",
    "tscv = TimeSeriesSplit(test_size = 1, max_train_size=16)\n",
    "\n",
    "# generating all of the data which we will iterate over during CV\n",
    "features_df = feat_generator.generate_features()\n",
    "\n",
    "# creating col lists for training\n",
    "cols_di={\n",
    "    'index': feat_generator.index_cols,\n",
    "    'target': feat_generator.target_col,\n",
    "    'feats': feat_generator.shifted_cols + feat_generator.roll_cols\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train months: [13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28], size: 120,494\n",
      "  Test months: [29],   size: 7,039\n",
      "  NRMSE:  1.0\n",
      "  RMSE :  5.1\n",
      "\n",
      "Fold 1:\n",
      "  Train months: [14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29], size: 119,696\n",
      "  Test months: [30],   size: 6,739\n",
      "  NRMSE:  1.0\n",
      "  RMSE :  4.4\n",
      "\n",
      "Fold 2:\n",
      "  Train months: [15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30], size: 118,557\n",
      "  Test months: [31],   size: 5,669\n",
      "  NRMSE:  1.0\n",
      "  RMSE :  4.4\n",
      "\n",
      "Fold 3:\n",
      "  Train months: [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31], size: 116,851\n",
      "  Test months: [32],   size: 5,439\n",
      "  NRMSE:  1.0\n",
      "  RMSE :  4.9\n",
      "\n",
      "Fold 4:\n",
      "  Train months: [17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32], size: 114,617\n",
      "  Test months: [33],   size: 5,668\n",
      "  NRMSE:  1.0\n",
      "  RMSE :  3.9\n",
      "\n",
      "\n",
      "------------------------------\n",
      "RMSE mean: 4.6\n",
      "NRMSE mean: 1.0\n"
     ]
    }
   ],
   "source": [
    "# initiating toy model\n",
    "toy_model = ToyModel()\n",
    "\n",
    "# iterating over CV folds\n",
    "toy_cv_res = run_cv(df=features_df, months_cv_split=tscv, model=toy_model, cols_di=cols_di, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train months: [13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28], size: 120,494\n",
      "  Test months: [29],   size: 7,039\n",
      "  NRMSE:  0.5\n",
      "  RMSE :  2.6\n",
      "\n",
      "Fold 1:\n",
      "  Train months: [14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29], size: 119,696\n",
      "  Test months: [30],   size: 6,739\n",
      "  NRMSE:  0.49\n",
      "  RMSE :  2.2\n",
      "\n",
      "Fold 2:\n",
      "  Train months: [15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30], size: 118,557\n",
      "  Test months: [31],   size: 5,669\n",
      "  NRMSE:  0.4\n",
      "  RMSE :  1.7\n",
      "\n",
      "Fold 3:\n",
      "  Train months: [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31], size: 116,851\n",
      "  Test months: [32],   size: 5,439\n",
      "  NRMSE:  0.69\n",
      "  RMSE :  3.4\n",
      "\n",
      "Fold 4:\n",
      "  Train months: [17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32], size: 114,617\n",
      "  Test months: [33],   size: 5,668\n",
      "  NRMSE:  0.71\n",
      "  RMSE :  2.7\n",
      "\n",
      "\n",
      "------------------------------\n",
      "RMSE mean: 2.5\n",
      "NRMSE mean: 0.56\n"
     ]
    }
   ],
   "source": [
    "# initiating lin model\n",
    "lin_model =  Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lin_model\", LinearRegression()) #ElasticNet() Lasso(alpha=.005) , \n",
    "])\n",
    "\n",
    "# iterating over CV folds\n",
    "lin_cv_res = run_cv(df=features_df, months_cv_split=tscv, model=lin_model, cols_di=cols_di, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.618315051373108"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tree_cv_res['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_optuna = features_df.sample(int(features_df.shape[0]*.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-20 07:08:03,256]\u001b[0m A new study created in memory with name: regression_2\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:12:26,268]\u001b[0m Trial 0 finished with value: 7.027438311927469 and parameters: {'max_depth': 9, 'learning_rate': 0.5494108848714635, 'n_estimators': 1048, 'gamma': 0.7314309627568815, 'reg_alpha': 6.881351625760832, 'reg_lambda': 0.3041189132619926, 'colsample_bytree': 0.8623198670552571}. Best is trial 0 with value: 7.027438311927469.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:14:49,778]\u001b[0m Trial 1 finished with value: 3.2398158214906063 and parameters: {'max_depth': 10, 'learning_rate': 0.12253799810128614, 'n_estimators': 635, 'gamma': 0.7550611110782909, 'reg_alpha': 0.790196904393736, 'reg_lambda': 3.4934281786530064, 'colsample_bytree': 0.5640316358786255}. Best is trial 1 with value: 3.2398158214906063.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:18:07,331]\u001b[0m Trial 2 finished with value: 5.0647887837327605 and parameters: {'max_depth': 10, 'learning_rate': 0.4943436270535506, 'n_estimators': 819, 'gamma': 0.5515932845886156, 'reg_alpha': 6.536841080745529, 'reg_lambda': 6.493237764251563, 'colsample_bytree': 0.604173232243729}. Best is trial 1 with value: 3.2398158214906063.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:20:44,576]\u001b[0m Trial 3 finished with value: 6.284899016994304 and parameters: {'max_depth': 5, 'learning_rate': 0.3634526352789033, 'n_estimators': 1198, 'gamma': 0.14274567324828474, 'reg_alpha': 1.5022482874718917, 'reg_lambda': 4.790006712571215, 'colsample_bytree': 0.8062964217713142}. Best is trial 1 with value: 3.2398158214906063.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:21:52,581]\u001b[0m Trial 4 finished with value: 4.584987799257994 and parameters: {'max_depth': 4, 'learning_rate': 0.559517281865469, 'n_estimators': 793, 'gamma': 0.8767137706934921, 'reg_alpha': 3.4500404438978336, 'reg_lambda': 1.368972935251891, 'colsample_bytree': 0.5533726531803304}. Best is trial 1 with value: 3.2398158214906063.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:21:58,577]\u001b[0m Trial 5 finished with value: 3.8572909157957085 and parameters: {'max_depth': 1, 'learning_rate': 0.3766563908618405, 'n_estimators': 140, 'gamma': 0.782452879479651, 'reg_alpha': 4.54445208530765, 'reg_lambda': 5.048394184374854, 'colsample_bytree': 0.8882648393372947}. Best is trial 1 with value: 3.2398158214906063.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:22:32,251]\u001b[0m Trial 6 finished with value: 3.719158627393907 and parameters: {'max_depth': 4, 'learning_rate': 0.27056391223216975, 'n_estimators': 277, 'gamma': 0.21702450518809316, 'reg_alpha': 3.522088377771814, 'reg_lambda': 2.0310942188539847, 'colsample_bytree': 0.9003557790186316}. Best is trial 1 with value: 3.2398158214906063.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:23:00,679]\u001b[0m Trial 7 finished with value: 3.6727450429678057 and parameters: {'max_depth': 5, 'learning_rate': 0.042326486520590394, 'n_estimators': 200, 'gamma': 0.2917258571151471, 'reg_alpha': 0.018040878476689472, 'reg_lambda': 4.7486076018574686, 'colsample_bytree': 0.8118351354389762}. Best is trial 1 with value: 3.2398158214906063.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:23:42,111]\u001b[0m Trial 8 finished with value: 3.2069517277936925 and parameters: {'max_depth': 6, 'learning_rate': 0.5433466535028508, 'n_estimators': 301, 'gamma': 0.8208018771431249, 'reg_alpha': 6.110609750864362, 'reg_lambda': 5.335393419384289, 'colsample_bytree': 0.5435533294368562}. Best is trial 8 with value: 3.2069517277936925.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:25:14,389]\u001b[0m Trial 9 finished with value: 3.705558273056198 and parameters: {'max_depth': 3, 'learning_rate': 0.2303369288984531, 'n_estimators': 1023, 'gamma': 0.7669912765084588, 'reg_alpha': 5.738206986241349, 'reg_lambda': 5.531858909806422, 'colsample_bytree': 0.8675700643289308}. Best is trial 8 with value: 3.2069517277936925.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:26:32,388]\u001b[0m Trial 10 finished with value: 3.6126201494582886 and parameters: {'max_depth': 7, 'learning_rate': 0.4471622760864993, 'n_estimators': 443, 'gamma': 0.9980879623459401, 'reg_alpha': 5.015752362858611, 'reg_lambda': 3.3771990948903885, 'colsample_bytree': 0.6754725493923066}. Best is trial 8 with value: 3.2069517277936925.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:27:55,440]\u001b[0m Trial 11 finished with value: 3.2828668951180524 and parameters: {'max_depth': 8, 'learning_rate': 0.12879156396063093, 'n_estimators': 529, 'gamma': 0.555168765436548, 'reg_alpha': 1.528328366506143, 'reg_lambda': 3.3855567691206754, 'colsample_bytree': 0.5043000470464123}. Best is trial 8 with value: 3.2069517277936925.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:29:49,202]\u001b[0m Trial 12 finished with value: 3.5057432436165583 and parameters: {'max_depth': 7, 'learning_rate': 0.1693747354509258, 'n_estimators': 677, 'gamma': 0.6354848070521457, 'reg_alpha': 2.145119032991947, 'reg_lambda': 6.966039453419692, 'colsample_bytree': 0.6661621020657158}. Best is trial 8 with value: 3.2069517277936925.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:31:46,105]\u001b[0m Trial 13 finished with value: 4.254037734741651 and parameters: {'max_depth': 10, 'learning_rate': 0.03539767190057791, 'n_estimators': 371, 'gamma': 0.3745378601313379, 'reg_alpha': 0.1018508271143026, 'reg_lambda': 2.5208070909804343, 'colsample_bytree': 0.9976997657921215}. Best is trial 8 with value: 3.2069517277936925.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:31:56,407]\u001b[0m Trial 14 finished with value: 3.125065960399067 and parameters: {'max_depth': 7, 'learning_rate': 0.1466239429900748, 'n_estimators': 68, 'gamma': 0.9906161334156207, 'reg_alpha': 3.21757310184006, 'reg_lambda': 4.107264480793156, 'colsample_bytree': 0.6293262081628356}. Best is trial 14 with value: 3.125065960399067.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:32:08,907]\u001b[0m Trial 15 finished with value: 3.3944157549143434 and parameters: {'max_depth': 6, 'learning_rate': 0.19957208411983224, 'n_estimators': 93, 'gamma': 0.9686967218636451, 'reg_alpha': 3.2131901200789956, 'reg_lambda': 5.90018909019873, 'colsample_bytree': 0.6710562738396593}. Best is trial 14 with value: 3.125065960399067.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:32:17,016]\u001b[0m Trial 16 finished with value: 3.777619647675001 and parameters: {'max_depth': 7, 'learning_rate': 0.32918777699404467, 'n_estimators': 55, 'gamma': 0.9002595062083837, 'reg_alpha': 4.738299058971157, 'reg_lambda': 4.408690991797128, 'colsample_bytree': 0.6201882394610003}. Best is trial 14 with value: 3.125065960399067.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:32:32,743]\u001b[0m Trial 17 finished with value: 4.9161285948606075 and parameters: {'max_depth': 2, 'learning_rate': 0.5988442168127317, 'n_estimators': 290, 'gamma': 0.39113845699775, 'reg_alpha': 2.391074211499051, 'reg_lambda': 4.142593884805895, 'colsample_bytree': 0.7309983813032956}. Best is trial 14 with value: 3.125065960399067.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:33:02,139]\u001b[0m Trial 18 finished with value: 3.1537723652753056 and parameters: {'max_depth': 6, 'learning_rate': 0.43296107823960134, 'n_estimators': 255, 'gamma': 0.8631541176303631, 'reg_alpha': 5.844632695452943, 'reg_lambda': 5.836385724616736, 'colsample_bytree': 0.5028189884830093}. Best is trial 14 with value: 3.125065960399067.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:34:23,147]\u001b[0m Trial 19 finished with value: 3.6488060953800074 and parameters: {'max_depth': 8, 'learning_rate': 0.4289948034573312, 'n_estimators': 473, 'gamma': 0.6449415571056802, 'reg_alpha': 4.345622906138234, 'reg_lambda': 6.028807507450619, 'colsample_bytree': 0.5089830690008784}. Best is trial 14 with value: 3.125065960399067.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:35:01,124]\u001b[0m Trial 20 finished with value: 3.421264238684624 and parameters: {'max_depth': 8, 'learning_rate': 0.28813191753624323, 'n_estimators': 195, 'gamma': 0.05400382973630491, 'reg_alpha': 5.437771480983637, 'reg_lambda': 2.675925086855597, 'colsample_bytree': 0.6140236342258647}. Best is trial 14 with value: 3.125065960399067.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:35:42,403]\u001b[0m Trial 21 finished with value: 3.339819348464996 and parameters: {'max_depth': 6, 'learning_rate': 0.4702504517559253, 'n_estimators': 307, 'gamma': 0.8955773801204234, 'reg_alpha': 6.095829913385739, 'reg_lambda': 5.280169171226621, 'colsample_bytree': 0.5451773765671535}. Best is trial 14 with value: 3.125065960399067.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:36:12,196]\u001b[0m Trial 22 finished with value: 3.618225006580861 and parameters: {'max_depth': 6, 'learning_rate': 0.5099969311682575, 'n_estimators': 208, 'gamma': 0.8578476698499582, 'reg_alpha': 4.0066006186901095, 'reg_lambda': 4.062441088744416, 'colsample_bytree': 0.5807222007107066}. Best is trial 14 with value: 3.125065960399067.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:36:16,454]\u001b[0m Trial 23 finished with value: 3.130940633492162 and parameters: {'max_depth': 4, 'learning_rate': 0.4040251865858363, 'n_estimators': 50, 'gamma': 0.9998597017742586, 'reg_alpha': 6.189185008141823, 'reg_lambda': 6.18209582432157, 'colsample_bytree': 0.501337972015834}. Best is trial 14 with value: 3.125065960399067.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:36:21,220]\u001b[0m Trial 24 finished with value: 3.0531043607549906 and parameters: {'max_depth': 4, 'learning_rate': 0.3972692247105122, 'n_estimators': 55, 'gamma': 0.9909195743925654, 'reg_alpha': 5.158175268916149, 'reg_lambda': 6.989668183338549, 'colsample_bytree': 0.5052015333458841}. Best is trial 24 with value: 3.0531043607549906.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:36:25,700]\u001b[0m Trial 25 finished with value: 3.617410362741963 and parameters: {'max_depth': 3, 'learning_rate': 0.38748628015303527, 'n_estimators': 54, 'gamma': 0.9626968266853789, 'reg_alpha': 5.231545944124871, 'reg_lambda': 6.906234443812274, 'colsample_bytree': 0.6491100010953074}. Best is trial 24 with value: 3.0531043607549906.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:36:39,862]\u001b[0m Trial 26 finished with value: 3.642479204811065 and parameters: {'max_depth': 4, 'learning_rate': 0.31623769824743486, 'n_estimators': 135, 'gamma': 0.9890078255131748, 'reg_alpha': 2.9423522419368537, 'reg_lambda': 6.495333939253576, 'colsample_bytree': 0.7323729440858373}. Best is trial 24 with value: 3.0531043607549906.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:37:12,453]\u001b[0m Trial 27 finished with value: 3.4773774246214395 and parameters: {'max_depth': 3, 'learning_rate': 0.24808504784872268, 'n_estimators': 397, 'gamma': 0.9344326376194321, 'reg_alpha': 6.984618335485266, 'reg_lambda': 6.468056242945479, 'colsample_bytree': 0.7016449405994001}. Best is trial 24 with value: 3.0531043607549906.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:37:19,390]\u001b[0m Trial 28 finished with value: 3.1662651304790344 and parameters: {'max_depth': 2, 'learning_rate': 0.08342404879145557, 'n_estimators': 121, 'gamma': 0.7051815985308801, 'reg_alpha': 4.122897919215308, 'reg_lambda': 6.247163317984579, 'colsample_bytree': 0.5895638240205221}. Best is trial 24 with value: 3.0531043607549906.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:38:21,345]\u001b[0m Trial 29 finished with value: 3.784095287718709 and parameters: {'max_depth': 5, 'learning_rate': 0.34963379966295577, 'n_estimators': 539, 'gamma': 0.7055686156838972, 'reg_alpha': 6.70478023967026, 'reg_lambda': 2.762697662921727, 'colsample_bytree': 0.5319386749686534}. Best is trial 24 with value: 3.0531043607549906.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:38:37,902]\u001b[0m Trial 30 finished with value: 4.174791288098069 and parameters: {'max_depth': 4, 'learning_rate': 0.40831922459928904, 'n_estimators': 162, 'gamma': 0.8205972916570918, 'reg_alpha': 2.6379169977675705, 'reg_lambda': 0.6436572100188092, 'colsample_bytree': 0.6358055545483857}. Best is trial 24 with value: 3.0531043607549906.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:38:43,482]\u001b[0m Trial 31 finished with value: 3.0437341377348712 and parameters: {'max_depth': 5, 'learning_rate': 0.43305486623810874, 'n_estimators': 51, 'gamma': 0.9119856796124187, 'reg_alpha': 5.865824261865978, 'reg_lambda': 5.6561778046937174, 'colsample_bytree': 0.5085575791542885}. Best is trial 31 with value: 3.0437341377348712.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:38:50,079]\u001b[0m Trial 32 finished with value: 3.6718461107701685 and parameters: {'max_depth': 5, 'learning_rate': 0.4713279297498098, 'n_estimators': 52, 'gamma': 0.9197150839227213, 'reg_alpha': 6.20944790129923, 'reg_lambda': 5.685874135062729, 'colsample_bytree': 0.5781204568238412}. Best is trial 31 with value: 3.0437341377348712.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:39:10,322]\u001b[0m Trial 33 finished with value: 3.3677315923433566 and parameters: {'max_depth': 4, 'learning_rate': 0.32812290355343426, 'n_estimators': 219, 'gamma': 0.9331911556741925, 'reg_alpha': 5.5289501974988, 'reg_lambda': 6.721605633468441, 'colsample_bytree': 0.5240802228910483}. Best is trial 31 with value: 3.0437341377348712.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:39:23,953]\u001b[0m Trial 34 finished with value: 3.7255503185772176 and parameters: {'max_depth': 5, 'learning_rate': 0.4022917014579809, 'n_estimators': 116, 'gamma': 0.9956447852347619, 'reg_alpha': 6.536703044135928, 'reg_lambda': 6.225358684036407, 'colsample_bytree': 0.5653315401543699}. Best is trial 31 with value: 3.0437341377348712.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:40:47,251]\u001b[0m Trial 35 finished with value: 3.9083098929224045 and parameters: {'max_depth': 3, 'learning_rate': 0.5052207806840464, 'n_estimators': 1017, 'gamma': 0.8247766226246385, 'reg_alpha': 3.8384548135011567, 'reg_lambda': 4.738202637872938, 'colsample_bytree': 0.6051237000192722}. Best is trial 31 with value: 3.0437341377348712.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:44:04,653]\u001b[0m Trial 36 finished with value: 3.021032927798774 and parameters: {'max_depth': 9, 'learning_rate': 0.005298559699829036, 'n_estimators': 857, 'gamma': 0.7744615794844047, 'reg_alpha': 4.7427786108127865, 'reg_lambda': 3.9464923699087713, 'colsample_bytree': 0.5556916732637939}. Best is trial 36 with value: 3.021032927798774.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:47:38,842]\u001b[0m Trial 37 finished with value: 3.039274750756352 and parameters: {'max_depth': 9, 'learning_rate': 0.08060104069981151, 'n_estimators': 847, 'gamma': 0.7432035092169504, 'reg_alpha': 4.931256192542855, 'reg_lambda': 3.8980539583894087, 'colsample_bytree': 0.5631747375049287}. Best is trial 36 with value: 3.021032927798774.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:51:19,252]\u001b[0m Trial 38 finished with value: 3.1543112657613097 and parameters: {'max_depth': 9, 'learning_rate': 0.06842652167557228, 'n_estimators': 896, 'gamma': 0.6453243470542984, 'reg_alpha': 4.889296994325116, 'reg_lambda': 3.703847459711918, 'colsample_bytree': 0.566011305908742}. Best is trial 36 with value: 3.021032927798774.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 07:55:21,966]\u001b[0m Trial 39 finished with value: 4.011820210940998 and parameters: {'max_depth': 9, 'learning_rate': 0.0220544603079447, 'n_estimators': 776, 'gamma': 0.7354833415657168, 'reg_alpha': 4.523088005311786, 'reg_lambda': 2.99013848455312, 'colsample_bytree': 0.782820289638315}. Best is trial 36 with value: 3.021032927798774.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 08:05:50,257]\u001b[0m Trial 40 finished with value: 2.940106771512302 and parameters: {'max_depth': 10, 'learning_rate': 0.0053376048013614175, 'n_estimators': 912, 'gamma': 0.5435250001685656, 'reg_alpha': 5.15061285982145, 'reg_lambda': 1.9793519623556088, 'colsample_bytree': 0.5372594056321844}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 08:13:26,703]\u001b[0m Trial 41 finished with value: 3.035607537271508 and parameters: {'max_depth': 10, 'learning_rate': 0.00973683681253706, 'n_estimators': 1119, 'gamma': 0.4894306759729554, 'reg_alpha': 5.30425131743773, 'reg_lambda': 1.8135163647841648, 'colsample_bytree': 0.5406077838742142}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 08:17:41,137]\u001b[0m Trial 42 finished with value: 3.003277224231705 and parameters: {'max_depth': 10, 'learning_rate': 0.008967387618001761, 'n_estimators': 1174, 'gamma': 0.4719214064800221, 'reg_alpha': 5.610944968746625, 'reg_lambda': 1.6764340741781671, 'colsample_bytree': 0.5380483711491698}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 08:22:04,497]\u001b[0m Trial 43 finished with value: 3.0644048033869504 and parameters: {'max_depth': 10, 'learning_rate': 0.011513038031604216, 'n_estimators': 1178, 'gamma': 0.473479795704793, 'reg_alpha': 4.808142547062807, 'reg_lambda': 1.6606333245617717, 'colsample_bytree': 0.5554084505781808}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 08:27:25,381]\u001b[0m Trial 44 finished with value: 3.2025095591555734 and parameters: {'max_depth': 10, 'learning_rate': 0.08488442811613536, 'n_estimators': 1136, 'gamma': 0.5164577794273629, 'reg_alpha': 5.40124317083637, 'reg_lambda': 0.9405092468096105, 'colsample_bytree': 0.5939661323819339}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 08:31:12,817]\u001b[0m Trial 45 finished with value: 3.0656790033967805 and parameters: {'max_depth': 9, 'learning_rate': 0.05563397708202574, 'n_estimators': 949, 'gamma': 0.43764034174933014, 'reg_alpha': 3.7142206157562763, 'reg_lambda': 0.1020975313145902, 'colsample_bytree': 0.537653416393948}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 08:35:15,746]\u001b[0m Trial 46 finished with value: 2.943459492304746 and parameters: {'max_depth': 10, 'learning_rate': 0.005394615117130764, 'n_estimators': 1104, 'gamma': 0.5636350435893736, 'reg_alpha': 4.545256600287754, 'reg_lambda': 2.189862492450162, 'colsample_bytree': 0.536834333405255}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 08:41:54,260]\u001b[0m Trial 47 finished with value: 3.999780664015695 and parameters: {'max_depth': 10, 'learning_rate': 0.005154388722316588, 'n_estimators': 1138, 'gamma': 0.5819145430453482, 'reg_alpha': 4.427224208220456, 'reg_lambda': 2.1711995800461836, 'colsample_bytree': 0.9356202843884344}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 08:46:17,269]\u001b[0m Trial 48 finished with value: 3.530867274382616 and parameters: {'max_depth': 10, 'learning_rate': 0.10734423899405476, 'n_estimators': 1090, 'gamma': 0.3352954884825716, 'reg_alpha': 5.584495232626388, 'reg_lambda': 1.4781924641841775, 'colsample_bytree': 0.5325302143502654}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 08:49:56,104]\u001b[0m Trial 49 finished with value: 3.241837883416467 and parameters: {'max_depth': 9, 'learning_rate': 0.043030801535463646, 'n_estimators': 973, 'gamma': 0.581228916514024, 'reg_alpha': 4.225520772677284, 'reg_lambda': 1.9518463411767246, 'colsample_bytree': 0.5938532470607797}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 08:53:26,079]\u001b[0m Trial 50 finished with value: 3.4365311877019815 and parameters: {'max_depth': 8, 'learning_rate': 0.10995944436437809, 'n_estimators': 1086, 'gamma': 0.4457332582237706, 'reg_alpha': 5.17844987847461, 'reg_lambda': 1.3497652885254972, 'colsample_bytree': 0.5240991843511656}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 08:56:25,025]\u001b[0m Trial 51 finished with value: 3.0290098200342217 and parameters: {'max_depth': 9, 'learning_rate': 0.02948283810733146, 'n_estimators': 850, 'gamma': 0.5154238719682791, 'reg_alpha': 4.831157437245693, 'reg_lambda': 1.0865274747825, 'colsample_bytree': 0.5584846554286664}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 08:59:57,859]\u001b[0m Trial 52 finished with value: 3.148371373447392 and parameters: {'max_depth': 10, 'learning_rate': 0.032001759934369614, 'n_estimators': 729, 'gamma': 0.509038679872016, 'reg_alpha': 4.655234746602356, 'reg_lambda': 1.0234039413016411, 'colsample_bytree': 0.5514323897761011}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 09:08:48,789]\u001b[0m Trial 53 finished with value: 3.2087395146799365 and parameters: {'max_depth': 9, 'learning_rate': 0.045177691043392004, 'n_estimators': 910, 'gamma': 0.23611957628503466, 'reg_alpha': 5.744082144257958, 'reg_lambda': 2.2963848194463394, 'colsample_bytree': 0.5807161846735729}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 09:17:54,793]\u001b[0m Trial 54 finished with value: 3.233035953210174 and parameters: {'max_depth': 10, 'learning_rate': 0.008374119424175772, 'n_estimators': 1038, 'gamma': 0.40410010485965286, 'reg_alpha': 5.086681139744734, 'reg_lambda': 1.787780724300532, 'colsample_bytree': 0.6426928491225282}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[32m[I 2023-06-20 09:21:27,989]\u001b[0m Trial 55 finished with value: 3.873714165907854 and parameters: {'max_depth': 9, 'learning_rate': 0.1479198964406925, 'n_estimators': 854, 'gamma': 0.5660913974262269, 'reg_alpha': 4.623645834702016, 'reg_lambda': 1.1431598356629018, 'colsample_bytree': 0.6126422465725272}. Best is trial 40 with value: 2.940106771512302.\u001b[0m\n",
      "\u001b[33m[W 2023-06-20 09:29:03,075]\u001b[0m Trial 56 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/igorchebuniaev/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/p3/4j53xc_50yv4yqz952bnybrm0000gn/T/ipykernel_13233/20209571.py\", line 14, in objective\n",
      "    tree_cv_res = run_cv(df=df_for_optuna, months_cv_split=tscv, model=xgb, cols_di=cols_di, verbose=0)\n",
      "  File \"/Users/igorchebuniaev/Documents/Обучение/Verious_repos/honest_home_assignment/src/utilities.py\", line 50, in run_cv\n",
      "    test_df = df[df['date_block_num'].isin(test_months)]\n",
      "  File \"/Users/igorchebuniaev/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/igorchebuniaev/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/igorchebuniaev/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/Users/igorchebuniaev/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/igorchebuniaev/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(tree_cv_res[\u001b[39m'\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     18\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m, study_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mregression_2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m)\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest parameters\u001b[39m\u001b[39m'\u001b[39m, study\u001b[39m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     _optimize(\n\u001b[1;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[26], line 14\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     12\u001b[0m xgb \u001b[39m=\u001b[39m XGBRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m     13\u001b[0m tscv \u001b[39m=\u001b[39m TimeSeriesSplit(test_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, max_train_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m tree_cv_res \u001b[39m=\u001b[39m run_cv(df\u001b[39m=\u001b[39;49mdf_for_optuna, months_cv_split\u001b[39m=\u001b[39;49mtscv, model\u001b[39m=\u001b[39;49mxgb, cols_di\u001b[39m=\u001b[39;49mcols_di, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     16\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(tree_cv_res[\u001b[39m'\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/Обучение/Verious_repos/honest_home_assignment/src/utilities.py:50\u001b[0m, in \u001b[0;36mrun_cv\u001b[0;34m(df, months_cv_split, model, cols_di, verbose)\u001b[0m\n\u001b[1;32m     47\u001b[0m train_df \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mdate_block_num\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(train_months)]\n\u001b[1;32m     48\u001b[0m test_df \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mdate_block_num\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(test_months)]\n\u001b[0;32m---> 50\u001b[0m model\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mtrain_df[cols_di[\u001b[39m'\u001b[39;49m\u001b[39mfeats\u001b[39;49m\u001b[39m'\u001b[39;49m]], y\u001b[39m=\u001b[39;49mtrain_df[cols_di[\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m]])\n\u001b[1;32m     51\u001b[0m y_true \u001b[39m=\u001b[39m test_df[cols_di[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     52\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X\u001b[39m=\u001b[39mtest_df[cols_di[\u001b[39m'\u001b[39m\u001b[39mfeats\u001b[39m\u001b[39m'\u001b[39m]])\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m (\n\u001b[1;32m   1017\u001b[0m     model,\n\u001b[1;32m   1018\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1024\u001b[0m )\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1026\u001b[0m     params,\n\u001b[1;32m   1027\u001b[0m     train_dmatrix,\n\u001b[1;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1037\u001b[0m )\n\u001b[1;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/RL_in_ksp--361CVkw/lib/python3.9/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, .6),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 30, 1500),\n",
    "        'gamma': trial.suggest_float('gamma', 0.01, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 7.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 7.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0)\n",
    "    }\n",
    "    xgb = XGBRegressor(**params)\n",
    "    tscv = TimeSeriesSplit(test_size = 1, max_train_size=16)\n",
    "    tree_cv_res = run_cv(df=df_for_optuna, months_cv_split=tscv, model=xgb, cols_di=cols_di, verbose=0)\n",
    "    \n",
    "    return np.mean(tree_cv_res['rmse'])\n",
    "\n",
    "study = optuna.create_study(direction='minimize', study_name='regression_2')\n",
    "study.optimize(objective, n_trials=500)\n",
    "print('Best parameters', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train months: [13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28], size: 120,633\n",
      "  Test months: [29],   size: 6,921\n",
      "  NRMSE:  0.49\n",
      "  RMSE :  2.5\n",
      "\n",
      "Fold 1:\n",
      "  Train months: [14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29], size: 119,621\n",
      "  Test months: [30],   size: 6,680\n",
      "  NRMSE:  0.45\n",
      "  RMSE :  2.0\n",
      "\n",
      "Fold 2:\n",
      "  Train months: [15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30], size: 118,304\n",
      "  Test months: [31],   size: 5,830\n",
      "  NRMSE:  0.42\n",
      "  RMSE :  1.8\n",
      "\n",
      "Fold 3:\n",
      "  Train months: [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31], size: 116,761\n",
      "  Test months: [32],   size: 5,343\n",
      "  NRMSE:  0.67\n",
      "  RMSE :  3.3\n",
      "\n",
      "Fold 4:\n",
      "  Train months: [17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32], size: 114,497\n",
      "  Test months: [33],   size: 5,671\n",
      "  NRMSE:  0.52\n",
      "  RMSE :  2.0\n",
      "\n",
      "\n",
      "------------------------------\n",
      "RMSE mean: 2.3\n",
      "NRMSE mean: 0.51\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(test_size = 1, max_train_size=16)\n",
    "params = {'max_depth': 7, 'learning_rate': 0.005298559699829036, 'n_estimators': 300, 'gamma': 0.7744615794844047, \n",
    "          'reg_alpha': 4.7427786108127865, 'reg_lambda': 3.9464923699087713, 'colsample_bytree': 0.5556916732637939}\n",
    "\n",
    "tree_model = XGBRegressor(**params) #\n",
    "\n",
    "tree_cv_res = run_cv(df=features_df, months_cv_split=tscv, model=tree_model, cols_di=cols_di, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE mean: 2.3\n",
    "NRMSE mean: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent NN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_in_ksp_new",
   "language": "python",
   "name": "rl_in_ksp_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
